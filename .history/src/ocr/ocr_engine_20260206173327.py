"""OCR å¼•æ“ - é€šè¿‡ Ollama è°ƒç”¨è§†è§‰å¤§æ¨¡å‹"""

from __future__ import annotations

import time
from typing import List, Optional

from src.models import PageContent, PageInfo, ElementType
from src.ocr.element_classifier import RuleBasedClassifier
from src.utils.file_ops import get_file_hash, safe_write_json, read_json, ensure_dir
from src.utils.logger import get_logger

from pathlib import Path

logger = get_logger(__name__)

# é»˜è®¤ OCR æç¤ºè¯
DEFAULT_PROMPT = (
    "è¯·å®Œæ•´è§£æè¿™ä¸€é¡µå­¦æœ¯è®ºæ–‡å†…å®¹ï¼š\n"
    "1. è¯†åˆ«æ‰€æœ‰æ–‡å­—ï¼Œä¿æŒåŸæœ‰æ®µè½ç»“æ„\n"
    "2. å¦‚æœæœ‰æ•°å­¦å…¬å¼ï¼Œè½¬æ¢ä¸ºLaTeXæ ¼å¼ï¼ˆç”¨$$åŒ…è£¹ï¼‰\n"
    "3. å¦‚æœæœ‰è¡¨æ ¼ï¼Œè½¬æ¢ä¸ºMarkdownè¡¨æ ¼\n"
    "4. å¦‚æœæœ‰å›¾ç‰‡/å›¾è¡¨ï¼Œæè¿°å…¶å†…å®¹å’Œå…³é”®ä¿¡æ¯\n"
    "5. æ ‡æ³¨ç« èŠ‚æ ‡é¢˜å±‚çº§ï¼ˆç”¨ # ## ### ç­‰ï¼‰\n"
    "\nè¾“å‡ºæ ¼å¼ï¼šMarkdown"
)


class VisionOCREngine:
    """é€šè¿‡ Ollama è°ƒç”¨è§†è§‰æ¨¡å‹çš„ OCR å¼•æ“ã€‚

    æ”¯æŒ qwen2.5vlã€minicpm-vã€llama3.2-vision ç­‰ Ollama å¤šæ¨¡æ€æ¨¡å‹ã€‚
    Ollama è‡ªè¡Œç®¡ç† GPU æ˜¾å­˜ï¼Œæ— éœ€æ‰‹åŠ¨åŠ è½½/å¸è½½æƒé‡ã€‚
    """

    def __init__(self) -> None:
        self._model_name = ""
        self._classifier = RuleBasedClassifier()

    @property
    def is_loaded(self) -> bool:
        return self._model_name != ""

    def load_model(self, model_name: str) -> None:
        """è®¾ç½®è¦ä½¿ç”¨çš„ Ollama è§†è§‰æ¨¡å‹ï¼Œå¹¶éªŒè¯å¯ç”¨æ€§ã€‚

        Args:
            model_name: Ollama æ¨¡å‹åç§°ï¼Œå¦‚ "qwen2.5vl:7b"
        """
        if self._model_name == model_name:
            logger.info("æ¨¡å‹å·²å°±ç»ªï¼Œè·³è¿‡: %s", model_name)
            return

        logger.info("éªŒè¯ Ollama OCR æ¨¡å‹: %s", model_name)

        try:
            import ollama
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
            models = ollama.list()
            available = [m.model for m in models.models]
            if not any(model_name in name for name in available):
                logger.warning(
                    "æ¨¡å‹ %s æœªåœ¨æœ¬åœ°æ‰¾åˆ° (å¯ç”¨: %s)ï¼Œé¦–æ¬¡è°ƒç”¨æ—¶ Ollama ä¼šè‡ªåŠ¨ä¸‹è½½",
                    model_name, ", ".join(available) or "æ— ",
                )
            self._model_name = model_name
            logger.info("OCR æ¨¡å‹å·²å°±ç»ª: %s", model_name)

        except ImportError:
            raise RuntimeError("éœ€è¦å®‰è£… ollama: pip install ollama")
        except Exception as e:
            raise RuntimeError("Ollama è¿æ¥å¤±è´¥ (ç¡®ä¿ ollama serve æ­£åœ¨è¿è¡Œ): {}".format(e))

    def process_page(
        self, image_path: str, page_num: int, prompt: Optional[str] = None, host: Optional[str] = None
    ) -> PageContent:
        """å¤„ç†å•é¡µå›¾åƒï¼ˆå¸¦ç»“æœç¼“å­˜ï¼‰ã€‚"""
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹æœªè®¾ç½®ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")

        import ollama
        # å¦‚æœæŒ‡å®šäº† hostï¼Œä½¿ç”¨ Client å¯¹è±¡ï¼›å¦åˆ™ä½¿ç”¨å…¨å±€é»˜è®¤
        client = ollama.Client(host=host) if host else ollama

        prompt = prompt or DEFAULT_PROMPT
        img_path = Path(image_path)
        
        # â”€â”€ ç¼“å­˜é€»è¾‘ â”€â”€
        # ç¼“å­˜è·¯å¾„: cache/ocr_results/{model_name}/{img_hash}.json
        img_hash = get_file_hash(img_path)
        cache_dir = ensure_dir(Path("cache/ocr_results") / self._model_name.replace(":", "_"))
        cache_path = cache_dir / f"{img_hash}.json"
        
        if cache_path.exists():
            try:
                cached_data = read_json(cache_path)
                logger.info("ğŸ¯ é¡µé¢ %d å‘½ä¸­ç¼“å­˜: %s", page_num, cache_path.name)
                return PageContent(
                    page_num=page_num,
                    markdown=cached_data["markdown"],
                    detected_elements=[ElementType(e) for e in cached_data["elements"]],
                    confidence=cached_data.get("confidence", 1.0)
                )
            except Exception as e:
                logger.warning("è¯»å–ç¼“å­˜å¤±è´¥: %s", e)

        # â”€â”€ å®é™…è¯·æ±‚ â”€â”€
        try:
            response = client.chat(
                model=self._model_name,
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                        "images": [str(img_path)],
                    }
                ],
                options={
                    "num_ctx": 4096,  # OCR é˜¶æ®µä¸éœ€è¦ 100k ä¸Šä¸‹æ–‡ï¼Œé™æ­»ä»¥èŠ‚çœå¹¶è¡Œæ˜¾å­˜
                    "temperature": 0, # æé«˜ OCR ç¨³å®šæ€§
                }
            )
            markdown = response.message.content.strip()

        except Exception as e:
            logger.error("é¡µé¢ %d OCR å¤±è´¥: %s", page_num, e)
            markdown = "[OCR å¤±è´¥: {}]".format(e)

        # å…ƒç´ åˆ†ç±»ï¼ˆçº¯ CPUï¼‰
        elements = self._classifier.classify(markdown)
        
        # ä¿å­˜ç¼“å­˜
        result = PageContent(
            page_num=page_num,
            markdown=markdown,
            detected_elements=elements,
            confidence=1.0 if "[OCR å¤±è´¥" not in markdown else 0.0,
        )
        
        if result.confidence > 0:
            try:
                safe_write_json(cache_path, {
                    "markdown": result.markdown,
                    "elements": [e.value for e in result.detected_elements],
                    "confidence": result.confidence,
                    "img_path": str(img_path)
                })
            except Exception as e:
                logger.warning("å†™å…¥ç¼“å­˜å¤±è´¥: %s", e)

        return result

    def process_all_pages(
        self, pages: List[PageInfo], show_progress: bool = True, parallel_threads: int = 1
    ) -> List[PageContent]:
        """æ‰¹é‡å¤„ç†æ‰€æœ‰é¡µé¢ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰ã€‚"""
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹æœªè®¾ç½®ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")
        
        # è®°å½•æœ¬æ¬¡ä½¿ç”¨çš„å¹¶è¡Œæ•°ï¼Œä¾›æ¸…ç†æ—¶ä½¿ç”¨
        self._last_parallel_count = parallel_threads
        total = len(pages)
        # ... (åç»­é€»è¾‘ä¿æŒä¸å˜)
        if parallel_threads <= 1:
            # ä¸²è¡Œå¤„ç† (åŸé€»è¾‘)
            results = []
            for i, page in enumerate(pages):
                import threading
                t0 = time.time()
                content = self.process_page(str(page.image_path), page.page_num)
                elapsed = time.time() - t0
                results.append(content)
                if show_progress:
                    logger.info(
                        "âŒ› [%d/%d] é¡µé¢ %d å®Œæˆ (ä¸²è¡Œ) | çº¿ç¨‹: %s | å¹¶è¡Œæ€»æ•°: 1", 
                        i + 1, total, page.page_num, threading.current_thread().name
                    )
            return results
        
        # å¹¶è¡Œå¤„ç†
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import threading
        logger.info("ğŸš€ å¯åŠ¨ç‰©ç†å¤šè·¯å¹¶è¡Œ OCR: è·¯æ•°=%d", parallel_threads)
        logger.info("ğŸ’¡ æç¤º: è¯·ç¡®ä¿ä½ å¯åŠ¨äº† %d ä¸ª Ollama æœåŠ¡ï¼Œç«¯å£ä» 11434 åˆ° %d", 
                    parallel_threads, 11434 + parallel_threads - 1)
        logger.info("   å¯åŠ¨å‚è€ƒ: OLLAMA_HOST=0.0.0.0:11435 ollama serve (å¹¶åœ¨ä¸åŒç»ˆç«¯å¯åŠ¨)")
        
        results = []

        # åˆ†é…ç«¯å£æ± 
        ports = [11434 + i for i in range(parallel_threads)]

        def _worker_wrapper(img_path, page_num, worker_idx):
            # å°†è¯¥çº¿ç¨‹å›ºå®šåˆ†é…åˆ°ä¸€ä¸ª Ollama å®ä¾‹ç«¯å£
            port = ports[worker_idx % parallel_threads]
            host = f"http://localhost:{port}"
            
            start_time = time.time()
            content = self.process_page(img_path, page_num, host=host)
            duration = time.time() - start_time
            
            t_name = threading.current_thread().name
            return content, t_name, duration, port

        with ThreadPoolExecutor(max_workers=parallel_threads) as executor:
            # å»ºç«‹ä»»åŠ¡åˆ—è¡¨
            future_to_page = {}
            for i, page in enumerate(pages):
                # ä¼ å…¥ä»»åŠ¡ç´¢å¼• i ç”¨äºç«¯å£åˆ†é…
                f = executor.submit(_worker_wrapper, str(page.image_path), page.page_num, i)
                future_to_page[f] = page.page_num
            
            # ä½¿ç”¨ as_completed ç›‘å¬è°å…ˆå®Œæˆ
            completed_count = 0
            for future in as_completed(future_to_page):
                page_num = future_to_page[future]
                try:
                    content, t_name, dur, used_port = future.result()
                    results.append(content)
                    completed_count += 1
                    if show_progress:
                        logger.info(
                            "âœ… [%d/%d] é¡µé¢ %d å®Œæˆ | è€—æ—¶: %.1fs | ç«¯å£: %d | çº¿ç¨‹: %s", 
                            completed_count, total, page_num, dur, used_port, t_name
                        )
                except Exception as e:
                    logger.error("âŒ é¡µé¢ %d å¤„ç†å¼‚å¸¸ (ç«¯å£ %d): %s", page_num, used_port if 'used_port' in locals() else 0, e)
            
            # æœ€ç»ˆåŠ¡å¿…æŒ‰é¡µç é‡æ’ï¼Œä¿è¯æ–‡æ¡£é€»è¾‘
            results.sort(key=lambda x: x.page_num)
            return results

    def unload_model(self) -> None:
        """é‡ç½®æ¨¡å‹åç§°ã€‚Ollama è‡ªè¡Œç®¡ç†æ˜¾å­˜ï¼Œæ— éœ€æ‰‹åŠ¨é‡Šæ”¾ã€‚"""
        self._model_name = ""
        logger.info("OCR æ¨¡å‹å·²é‡Šæ”¾")
